{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas Library\n",
    "Pandas is a powerful Python library used for data manipulation and analysis.\\\n",
    "It provides data structures and functions designed to make working with structured data fast, easy, and expressive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(pd) #For extensive documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Exploring Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(r\"C:\\Users\\chide\\Documents\\Datasets\\Titanic Dataset.csv\") #read data with pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head() #preview the data from the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.tail() #preview the data from the last row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic # you can only preview a certain number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None) #for displaying maximum rows\n",
    "pd.set_option('display.max_columns', None) #for displaying maximum columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Rows and Columns\n",
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe() #statistic Summary of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info() #summary of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = titanic[['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age','Ticket', 'Fare', 'Cabin']]\n",
    "selected_columns.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[(titanic['Pclass'] == 1) & (titanic['Sex'] == 'male')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(['Cabin', 'Fare'], axis =1, inplace = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling and Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_age = titanic['Age'].isnull() #check the amount of nulls in Age column\n",
    "nulls_age_count = nulls_age.sum()\n",
    "nulls_age_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_age_prev = titanic[titanic['Age'].isnull()] #previewing the nulls in the age data frame\n",
    "nulls_age_prev.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_cabin = titanic['Cabin'].isnull() #check the amount of nulls in Cabin column\n",
    "nulls_cabin.sum() \n",
    "#len(titanic)- nulls_cabin.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_cabin_prev = titanic[titanic['Cabin'].isnull()] #previewing the nulls in the age data frame\n",
    "nulls_cabin_prev.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class work: find the number of null values in the \"Embark column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a FOR LOOP to get the Columns that have Nulls and how many null values they have\n",
    "for column in titanic.columns:\n",
    "    #check for null values\n",
    "    if titanic[column].isnull().sum() > 0:\n",
    "        print(f'{column} has {titanic[column].isnull().sum()} Null values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing Values depends on a number of factors:\n",
    "\n",
    "Understand the Nature of Missing Data:\\\n",
    "Before deciding on a strategy to handle missing values, it's crucial to understand why the data is missing. \\\n",
    "Missing data can occur for various reasons, such as data entry errors, equipment malfunctions, or genuine absence of information.\\\n",
    "Understanding the patterns and reasons behind missing values can inform your choice of handling strategy.\n",
    "\n",
    "Imputation:\\\n",
    "Imputation involves filling in missing values with estimated or calculated values. \n",
    "Common techniques for imputation include replacing missing numerical values with the mean, median, or mode of the column,\\\n",
    "or using more sophisticated methods like regression or k-nearest neighbors (KNN) imputation.\\\n",
    "For categorical variables, missing values can be replaced with the most frequent category.\n",
    "\n",
    "Drop Missing Values:\\\n",
    "If missing values are few in number or occur randomly, you may opt to drop rows or columns containing missing values.\\\n",
    "This approach is suitable when the missing values do not represent a significant portion of the dataset and removing them does not introduce bias into the analysis.\\\n",
    "However, be cautious when dropping data, as it may lead to loss of valuable information.\n",
    "\n",
    "Use Advanced Imputation Techniques:\\\n",
    "Advanced imputation techniques take into account the relationships between variables and the underlying structure of the data.\\\n",
    "For example, you can use predictive models such as decision trees or random forests to predict missing values based on other variables in the dataset.\\\n",
    "Multiple imputation methods, such as the MICE (Multiple Imputation by Chained Equations) algorithm, generate several imputed datasets to capture uncertainty in the imputation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Embarked'].isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic[titanic['Embarked'].isnull()] # create a variable and store the 2 NaN values\n",
    "titanic_df.dropna(inplace = True) # Use inplace to actually drop NA from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dropna(subset = ['Embarked'], inplace = True) # To delete selected Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Embarked'].isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for duplicates\n",
    "\n",
    "Tagging a value 'duplicate' depends on the kind of data you are working with.\\\n",
    "example sales data might record multiple sales for a particulatr product. those should not be treated as duplicates.\\\n",
    "It is always better to check for duplicates on the index column or ID column because these cannot be recorded more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic['PassengerId'].duplicated().sum() # Check the ID column\n",
    "titanic.duplicated(subset = ['PassengerId']).sum() #its always better to check individual columns for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.duplicated(subset = ['Pclass']).sum()\n",
    "#Check the Pclass column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a FOR LOOP to print out the columns that have duplicate values\n",
    "\n",
    "for column in titanic.columns:\n",
    "    if titanic.duplicated(subset = [column]).sum() > 0:\n",
    "        print(f'{column} has {titanic[column].duplicated().sum()} duplicates') #notice that Ticket has Duplicate values which shuldnt be so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = titanic[titanic['Ticket'].duplicated()]\n",
    "check\n",
    "#check['Ticket'].value_counts()\n",
    "\n",
    "#len(check['Ticket'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop_duplicates(subset = ['Ticket'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correcting Data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'] = titanic['Age'].astype(int) #tried to convert to INT but failed because of Nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIll the Nan\n",
    "\n",
    "titanic['Age'].fillna(0, inplace = True) # Populating Your data with 0 can skew your analysis especially if you are going to be taking an Average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'] = titanic['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Survived'].unique() #see the uniques value in Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Pclass'].unique() #see the uniques value in Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Survived'] = titanic['Survived'].replace({0 : 'Died', 1 : 'Survived'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Pclass'] = titanic['Pclass'].replace({3 : 'Lower Class', 2 : 'Middle Class', 1 : 'Upper Class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class work, replace the Embarked Column like so:\n",
    "#C: Cherbourg\n",
    "#Q: Queenstown\n",
    "#S: Southampton\n",
    "\n",
    "# Capitalize the content of the Sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Embarked'] = titanic['Embarked'].replace({'C' : 'Cherbourg', 'Q' : 'Queenstown', 'S' : 'Southampton'})\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Sex'] = titanic['Sex'].str.capitalize()\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_titanic_dataset():\n",
    "    titanic = pd.read_csv(r\"C:\\Users\\chide\\Documents\\Datasets\\Titanic Dataset.csv\")\n",
    "    titanic = titanic[['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
    "       'Parch','Fare', 'Cabin', 'Embarked']]\n",
    "    titanic['Age'].fillna(0, inplace = True)\n",
    "    titanic['Cabin'].fillna('No data', inplace = True)\n",
    "    titanic.dropna(subset = ['Embarked'], inplace = True)\n",
    "    titanic['Embarked'] = titanic['Embarked'].replace({'C' : 'Cherbourg', 'Q' : 'Queenstown', 'S' : 'Southampton'})\n",
    "    return titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Embarked'].value_counts() #BEcause  we have previously dropped the Null values, we can trust these figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-1, 12, 19, 26, 35, 45, 55, 65, 75, 80]\n",
    "labels = ['0-12', '13-19', '20-26', '27-35', '36-45', '46-55', '56-65', '66-75', '75+']\n",
    "\n",
    "titanic['Age Groups'] = pd.cut(titanic['Age'], bins = bins, labels = labels)\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic['Age Groups'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data with conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to look at the data for only people in the first class who died.\n",
    "\n",
    "#titanic.loc[(titanic['Pclass'] == 1) & (titanic['Sex'] == 'male')]\n",
    "\n",
    "#or\n",
    "\n",
    "first_class_dead = titanic[(titanic['Pclass'] == 'Upper Class') & (titanic['Survived'] == 'Died')]\n",
    "first_class_dead.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data with a delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[['Name1', 'Name2']] = titanic['Name'].str.split(',', expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Netflix dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = r\"C:\\Users\\chide\\Documents\\Datasets\\netflix titles\\netflix_titles.csv\"\n",
    "netflix = pd.read_csv(file, encoding = 'latin1')\n",
    "netflix.head(10) #encoding issue = Encoding is the process of converting data from one format to another, In the context of text files, encoding refers to how characters are represented as bytes\n",
    "#Example iso-8859-1, UTF-8, ASCII, latin1,  etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\chide\\Documents\\Datasets\\netflix titles\\netflix_titles.csv\"\n",
    "netflix = pd.read_csv(file, encoding = 'iso-8859-1')\n",
    "netflix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many rows and columns\n",
    "#How many movies alltogether\n",
    "#remove unwanted columns including the cast column\n",
    "#check for nulls and fill nulls\n",
    "#check for duplicates and drop duplicate\n",
    "#correct data types\n",
    "#How many movies per rating category\n",
    "#How many unique countries are recorded\n",
    "\n",
    "#BOnus Questions\n",
    "#countries that have more than 100 movies\n",
    "#order the data by the year starting from the earliest movie\n",
    "#How long ago was each movie released, create a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(netflix)\n",
    "netflix.shape\n",
    "\n",
    "no_rows = netflix.shape[0]\n",
    "no_columns = netflix.shape[1]\n",
    "\n",
    "print(f'There are {no_rows} rows and {no_columns} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_movies = netflix[netflix['type'] == 'Movie'].shape[0]\n",
    "\n",
    "print(f'There are {no_movies} movies alltogether')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix = netflix[['show_id','type','title','director','country','date_added','release_year','rating','duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = netflix.columns\n",
    "\n",
    "for column in columns:\n",
    "    no_nulls = netflix[column].isnull().sum()\n",
    "    if no_nulls > 0:\n",
    "        print(f'{column} has {no_nulls} null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix[netflix['director'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix['director'].fillna('No data', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nulls using For loop and IF statement\n",
    "columns = netflix.columns\n",
    "\n",
    "for column in columns:\n",
    "    no_nulls = netflix[column].isnull().sum()\n",
    "    data_type = netflix[column].dtype\n",
    "    if no_nulls > 0 and data_type == 'object':\n",
    "        netflix[column].fillna('No data', inplace = True)\n",
    "    else:\n",
    "        netflix[column].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "netflix.duplicated(subset = ['show_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix['country'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countries that have more than 100 movies\n",
    "netflix['country'].value_counts()[netflix['country'].value_counts() > 100] \n",
    "\n",
    "#or \n",
    "\n",
    "country_count = netflix['country'].value_counts()\n",
    "country_count[country_count > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order the data by the year starting from the earliest movie\n",
    "netflix.head(10).sort_values(by = 'release_year', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How long ago was each movie released, create a new column\n",
    "import datetime\n",
    "#netflix.head(10)\n",
    "\n",
    "netflix['movie age'] = datetime.datetime.now().year - netflix['release_year']\n",
    "netflix.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating and Grouping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Determine how many rows and columns are in the dataset.\n",
    "Remove any unwanted columns that do not contribute to analysis (like 'Invoice ID' if deemed irrelevant).\n",
    "\n",
    "Check for any null values in each column and handle them appropriately (either fill them or drop them).\n",
    "Identify any duplicate rows in the dataset and remove them if necessary.\n",
    "Correct data types if needed (e.g., ensure 'Date' and 'Time' are in datetime format).\n",
    "\n",
    "Calculate total sales per product line.\n",
    "Analyze the average rating for each product line.\n",
    "Determine the average tax and total cost paid per customer type and by gender.\n",
    "Examine sales data by branch and city to find out which branch is performing best.\n",
    "Group data by payment method to see the preferred payment method for each customer type\n",
    "\n",
    "Identify which month of the year had the highest sales total.\n",
    "Create a new column that classifies transactions as 'High' or 'Low' sales based on a predefined threshold of total amount.\n",
    "Calculate the total units sold per branch and compare these figures..\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmat = pd.read_csv(r\"C:\\Users\\chide\\Documents\\Datasets\\DWBB Academy - Matplotlib and seaborn class\\supermarket_sales - Sheet1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns = walmat.shape\n",
    "print(f\"The dataset has {rows} rows and {columns} columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmat.drop(['Invoice ID'], axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "walmat.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmat.duplicated(subset =['Invoice ID']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmat.drop_duplicates(subset =['Invoice ID'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmat['Date'] = pd.to_datetime(walmat['Date'])\n",
    "walmat['Time'] = pd.to_datetime(walmat['Time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmat['Product line'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total sales per product line\n",
    "total_sales_per_product_line = walmat.groupby('Product line')['Total'].sum()\n",
    "round(total_sales_per_product_line, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average tax and total cost paid per customer type and by gender\n",
    "average_tax_per_customer_type = walmat.groupby('Customer type')['Tax 5%'].mean()\n",
    "total_cost_per_customer_type = walmat.groupby('Customer type')['Total'].sum()\n",
    "\n",
    "average_tax_per_gender = walmat.groupby('Gender')['Tax 5%'].mean()\n",
    "total_cost_per_gender = walmat.groupby('Gender')['Total'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_tax_per_customer_type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost_per_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine sales data by branch and city - Class Excercise\n",
    "sales_per_branch = walmat.groupby('Branch')['Total'].sum()\n",
    "sales_per_city = walmat.groupby('City')['Total'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total units sold per branch and compare these figures - Class Excercise\n",
    "total_units_sold_per_branch = walmat.groupby('Branch')['Quantity'].sum()\n",
    "total_units_sold_per_branch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by payment method to see the preferred payment method for each customer type\n",
    "preferred_payment_method = walmat.groupby(['Customer type', 'Payment']).size().unstack()\n",
    "preferred_payment_method\n",
    "\n",
    "# Transpose Dataframe\n",
    "# preferred_payment_method.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which month of the year had the highest sales total - Class Excercise\n",
    "walmat['Month'] = walmat['Date'].dt.month\n",
    "highest_sales_month = walmat.groupby('Month')['Total'].sum()\n",
    "\n",
    "highest_sales_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that classifies transactions as 'High' or 'Low' sales\n",
    "threshold = 500 \n",
    "walmat['Sales Cat'] = walmat['Total'].apply(lambda x: 'High' if x > threshold else 'Low')\n",
    "\n",
    "walmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
